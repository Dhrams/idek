
In order to use this file, activate org-babel for ipython and press C-c C-c to execute code blocks.


First we import number and set its random seed to a fixed number for reproducibility.
#+BEGIN_SRC ipython :session
import numpy as np
# For reproducibility
np.random.seed(123)

from keras import backend as K
import os

def set_keras_backend(backend):

    if K.backend() != backend:
        os.environ['KERAS_BACKEND'] = backend
        import importlib
        importlib.reload(K)
        assert K.backend() == backend

set_keras_backend("theano")
#+END_SRC

#+RESULTS:
: # Out[32]:

Plotting the first image in the training data so that we have an idea of what we're looking at.
#+BEGIN_SRC ipython :session :results raw drawer
%matplotlib inline
# Visualize data
from matplotlib import pyplot as plt
# plt.imshow(X_train[0])
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[33]:
:END:


#+BEGIN_SRC ipython :noweb yes :session :exports none
# Class Definition of Neural Net
<<NeuralNet>>
#+END_SRC

#+RESULTS:
: # Out[34]:

#+BEGIN_SRC ipython :session
net = NeuralNet(input_node_size = 784,
                output_node_size = 10,
                hidden_layers_node_size = [512])
#+END_SRC

#+RESULTS:
: # Out[35]:

#+BEGIN_SRC ipython :session
# net.train(X_train, Y_train, epochs=6)
#+End_SRC

#+RESULTS:
: # Out[36]:



* NeuralNet
#+NAME: NeuralNet
#+BEGIN_SRC python :noweb yes :tangle neural.py
  class NeuralNet(object):

      def __init__(self,
                   input_node_size = None,               # Number of nodes in input layer
                   output_node_size = None,              # Number of nodes in output layer
                   input_shape = None,
                   hidden_layers_node_size = []          # Number of nodes in each hidden layer
                  ):
                      <<NeuralNet_init>>
      <<NeuralNet_train>>
      <<NeuralNet_run>>
      <<NeuralNet_label>>
#+END_SRC

** init
The Sequential model is a linear stack of layers. We pass in a list of layer instances to it to make a Neural Net.
#+NAME: NeuralNet_init
#+BEGIN_SRC python
          from keras.models import Sequential
          self.model = Sequential()
#+END_SRC

Let's import the core layers from Keras which are almost always used.
#+NAME: NeuralNet_init
#+BEGIN_SRC python
          from keras.layers import Dense, Dropout, Activation, Flatten, LSTM
#+END_SRC

The model should know what input shape it should expect. For this reason, we sepcifiy an input size for the first layer.
#+NAME: NeuralNet_init
#+BEGIN_SRC python
          # First layer requires input dimension ie input_shape
          self.model.add(
                         LSTM(units=64,
                               input_dim=input_node_size
                               )
                         )
          self.model.add(Activation('relu'))
#+END_SRC

#+NAME: NeuralNet_init
#+BEGIN_SRC python
          # Add layers to model for all hidden layers
          for node_size in hidden_layers_node_size:
              self.model.add(
                             Dense(units=node_size)
                            )
              self.model.add(Activation('relu'))
              self.model.add(Dropout(0.3))
#+END_SRC

Adding a regularizer does not improve the model
#+NAME: NeuralNet_init
#+BEGIN_SRC python
#          from keras import regularizers
#          self.model.add(Dense(64,
#                          input_dim=64,
#                          kernel_regularizer=regularizers.l2(0.01),
#                          activity_regularizer=regularizers.l1(0.01))
#                   )
#+END_SRC

#+NAME: NeuralNet_init
#+BEGIN_SRC python
          # Last layer requires activation to be softmax
          self.model.add(
                         Dense(units=output_node_size,
                               activation='softmax'
                               )
                        )
#+END_SRC


#+NAME: NeuralNet_init
#+BEGIN_SRC python
          # Compile model
          self.model.compile(loss='categorical_crossentropy',
                             optimizer='adam',
                             metrics=['accuracy'])
          #model.fit(x_train, y_train, epochs=5, batch_size=32)
#+END_SRC






** train

fit the model with training datasets

inputs:
train_x - training data
train_y - training labels
epochs - number of iterations over the entirity of both the x and y data desired

returns:
Nothing

#+NAME: NeuralNet_train
#+BEGIN_SRC python
    def train(self, train_x, train_y, epochs):
        self.model.fit(train_x, train_y, epochs, batch_size = 32)
#+END_SRC

** run


evaluates the model with test data

inputs:
X - test data
Y - test labels
steps - number of iterations over the entire dataset before evaluation is completed

returns:
metrics - the test losses as well as the metric defined in __init__, which in this case is accuracy

#+NAME: NeuralNet_run
#+BEGIN_SRC python
    def run(self, X, Y, steps):
        metrics = []
        metrics = self.model.evaluate(X, Y, batch_size = 32, steps = steps)
        return metrics
#+END_SRC


** label

predicts the labels of the data given

Inputs:
X - unlabeled test data
steps - number of iterations over the entire dataset before evaluation is completed

returns:
predictions - a numpy array of predictions
 
#+NAME: NeuralNet_label
#+BEGIN_SRC python
    def label(self, X, steps):
        predictions = self.model.predict(X, batch_size = 32, steps = steps)
        return predictions
#+END_SRC










